---
version: '3.7'

services:

  elasticsearch:
    image: "blacktop/elasticsearch:{{ elastic_version }}"
    environment:
      - "ES_JAVA_OPTS=-Xms{{ elasticsearch_memory }}m -Xmx{{ elasticsearch_memory }}m"
    configs:
      - source: elasticsearch.yml
        target: /usr/share/elasticsearch/config/elasticsearch.yml
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      restart_policy:
        condition: any
        delay: 5s
        window: 30s
      resources:
        limits:
          memory: "{{ elasticsearch_memory }}M"
        reservations:
          memory: "{{ elasticsearch_memory_reservation }}M"
      labels:
        - "traefik.frontend.rule=Host:{{ elasticsearch_domain }}"
        - traefik.enable=true
        - traefik.port=9200
        - "traefik.tags={{ traefik_public_tag }}"
        - "traefik.docker.network={{ traefik_network }}"
        # Traefik service that listens to HTTP
        - traefik.redirectorservice.frontend.entryPoints=http
        - traefik.redirectorservice.frontend.redirect.entryPoint=https
        # Traefik service that listens to HTTPS
        - traefik.webservice.frontend.entryPoints=https
        # security labels
        - traefik.frontend.headers.browserXSSFilter=true
        - traefik.frontend.headers.frameDeny=true
        - traefik.frontend.headers.contentTypeNosniff=true
        # HSTS
        - traefik.frontend.headers.SSLRedirect=true
        - "traefik.frontend.headers.SSLHost={{ elasticsearch_domain }}"
        - traefik.frontend.headers.STSSeconds=315360000
        - traefik.frontend.headers.STSIncludeSubdomains=true
        - traefik.frontend.headers.STSPreload=true
        # Auth
        - "traefik.frontend.auth.basic.users={{ backend_users|join(',') | replace('$', '$$') }}"
        - "traefik.frontend.whiteList.sourceRange={{ trusted_backend_ips|join(',') }},127.0.0.1"
    networks:
      - stack
      - {{ traefik_network }}
    volumes:
      - 'es_data:/usr/share/elasticsearch/data'
    healthcheck:
      test: curl -s http://localhost:9200 >/dev/null; if [[ $$? == 52 ]]; then echo 0; else echo 1; fi
      interval: 30s
      timeout: 10s
      retries: 5

  kibana:
    image: "blacktop/kibana:{{ elastic_version }}"
    configs:
      - source: kibana.yml
        target: /usr/share/kibana/config/kibana.yml
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      restart_policy:
        condition: any
        delay: 5s
        window: 15s
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M
      labels:
        - "traefik.frontend.rule=Host:{{ kibana_domain }}"
        - traefik.enable=true
        - traefik.port=5601
        - "traefik.tags={{ traefik_public_tag }}"
        - "traefik.docker.network={{ traefik_network }}"
        # Traefik service that listens to HTTP
        - traefik.redirectorservice.frontend.entryPoints=http
        - traefik.redirectorservice.frontend.redirect.entryPoint=https
        # Traefik service that listens to HTTPS
        - traefik.webservice.frontend.entryPoints=https
        # security labels
        - traefik.frontend.headers.browserXSSFilter=true
        - traefik.frontend.headers.frameDeny=true
        - traefik.frontend.headers.contentTypeNosniff=true
        # HSTS
        - traefik.frontend.headers.SSLRedirect=true
        - "traefik.frontend.headers.SSLHost={{ kibana_domain }}"
        - traefik.frontend.headers.STSSeconds=315360000
        - traefik.frontend.headers.STSIncludeSubdomains=true
        - traefik.frontend.headers.STSPreload=true
        # Auth
        - "traefik.frontend.auth.basic.users={{ backend_users|join(',') | replace('$', '$$') }}"
        - "traefik.frontend.whiteList.sourceRange={{ trusted_backend_ips|join(',') }},127.0.0.1"
    networks:
      - stack
      - {{ traefik_network }}
    healthcheck:
      test: curl -s http://localhost:5601 >/dev/null; if [[ $$? == 52 ]]; then echo 0; else echo 1; fi
      interval: 30s
      timeout: 10s
      retries: 5

  # process logs from everywhere
  logstash:
    image: "elastic/logstash:{{ elastic_official_version }}"
    configs:
      - source: logstash.conf
        target: /usr/share/logstash/pipeline/logstash.conf
      - source: logstash.yml
        target: /usr/share/logstash/config/logstash.yml
    secrets:
      - source: logstash-rootCA.crt
        target: /etc/ca.crt
      - source: logstash-certificate.crt
        target: /etc/server.crt
      - source: logstash-private-key.key
        target: /etc/server.key
    environment:
      - "LS_JAVA_OPTS=-Xms{{ logstash_memory }}m -Xmx{{ logstash_memory }}m"
    ports: # in order to receive logs from allowed origins, theses ports are opened, access are filtered using UFW
      - target: 5000 # tcp
        published: 5000
        mode: host
      - target: 5044 # beats
        published: 5044
        mode: host
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      restart_policy:
        condition: any
        delay: 5s
        window: 30s
      resources:
        limits:
          memory: "{{ logstash_memory }}M"
      labels:
        - "traefik.frontend.rule=Host:{{ logstash_domain }}"
        - traefik.enable=true
        - traefik.port=8080
        - "traefik.tags={{ traefik_public_tag }}"
        - "traefik.docker.network={{ traefik_network }}"
        # Traefik service that listens to HTTP
        - traefik.redirectorservice.frontend.entryPoints=http
        - traefik.redirectorservice.frontend.redirect.entryPoint=https
        # Traefik service that listens to HTTPS
        - traefik.webservice.frontend.entryPoints=https
        # security labels
        - traefik.frontend.headers.browserXSSFilter=true
        - traefik.frontend.headers.frameDeny=true
        - traefik.frontend.headers.contentTypeNosniff=true
        # HSTS
        - traefik.frontend.headers.SSLRedirect=true
        - "traefik.frontend.headers.SSLHost={{ logstash_domain }}"
        - traefik.frontend.headers.STSSeconds=315360000
        - traefik.frontend.headers.STSIncludeSubdomains=true
        - traefik.frontend.headers.STSPreload=true
        # Auth => here we can configure access for other clusters to submit logs
        - "traefik.frontend.auth.basic.users={{ backend_users|join(',') | replace('$', '$$') }}" # todo : configure accounts for other services (other clusters)
        - "traefik.frontend.whiteList.sourceRange={{ trusted_backend_ips|join(',') }},127.0.0.1" # todo : configure trusted cluster ips
    networks:
      - stack
      - {{ traefik_network }}
    healthcheck:
      test: curl -s http://localhost:8082 >/dev/null; if [[ $$? == 52 ]]; then echo 0; else echo 1; fi
      interval: 30s
      timeout: 10s
      retries: 5

  # check if services are up
  heartbeat:
    image: "elastic/heartbeat:{{ elastic_official_version }}"
    command: --strict.perms=false -e  # -e flag to log to stderr and disable syslog/file output
    configs:
      - source: heartbeat.yml
        target: /usr/share/heartbeat/heartbeat.yml
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      restart_policy:
        condition: any
        delay: 5s
        window: 15s
      resources:
        limits:
          memory: 64M
    networks:
      - stack
    healthcheck:
      test: heartbeat test config
      interval: 30s
      timeout: 15s
      retries: 5

networks:
  stack: # encrypted if Swarm want to split services on managers
    driver: overlay
    driver_opts:
      encrypted: ""
  {{ traefik_network }}:
    external: true

# use docker volume to persist ES data outside of a container.
volumes:
  es_data: {}

# documentation about keystore https://nicklang.com/posts/learning-to-love-the-keystore
# an other way to store sensible information but in this case, the user of the docker-cluster already have privileged access
configs: # config are immutable :/
  logstash.conf:
    name: "{{ docker_elastic_stack_name }}_logstash-${DEPLOY_TIMESTAMP}.conf"
    file: ./config/logstash/pipeline/logstash.conf
  logstash.yml:
    name: "{{ docker_elastic_stack_name }}_logstash-${DEPLOY_TIMESTAMP}.yml"
    file: ./config/logstash/logstash.yml
  elasticsearch.yml:
    name: "{{ docker_elastic_stack_name }}_elasticsearch-${DEPLOY_TIMESTAMP}.yml"
    file: ./config/elasticsearch/elasticsearch.yml
  kibana.yml:
    name: "{{ docker_elastic_stack_name }}_kibana-${DEPLOY_TIMESTAMP}.yml"
    file: ./config/kibana/kibana.yml
  heartbeat.yml:
    name: "{{ docker_elastic_stack_name }}_heartbeat-${DEPLOY_TIMESTAMP}.yml"
    file: ./config/heartbeat/heartbeat.yml

secrets:
  logstash-rootCA.crt:
    name: "{{ docker_elastic_stack_name }}_logstash-rootCA-${DEPLOY_TIMESTAMP}.crt"
    file: "./{{ logstash_certificates_relative_directory }}/{{ logstash_root_CA_certificate_name }}"
  logstash-certificate.crt:
    name: "{{ docker_elastic_stack_name }}_logstash-certificate-${DEPLOY_TIMESTAMP}.crt"
    file: "./{{ logstash_certificates_relative_directory }}/{{ logstash_node_certificate_name }}.crt"
  logstash-private-key.key:
    name: "{{ docker_elastic_stack_name }}_logstash-private-key-${DEPLOY_TIMESTAMP}.key"
    file: "./{{ logstash_certificates_relative_directory }}/{{ logstash_node_certificate_name }}.key"
